\section{Исследовательская часть}

В этом разделе приведены результаты исследования поведения инфраструктуры выбранной системы управления базами данных при высоких нагрузках, технические характеристики устройства, на котором проводилось исследование, и средства проведения исследования. По результатам проведённого исследования составлено заключение, включающее установленную зависимость производительности системы от объёма предоставляемой кэш-памяти.

\subsection{Технические характеристики}

Исследование проводилось на ноутбуке при включённом режиме производительности и питании от сети. Во время исследования ноутбук был нагружен только системными процессами. Помещение и место проведения исследования предварительно были подготовлены во избежание перегрева технических элементов ноутбука. Технические характеристики устройства, на котором проводилось исследование:

\begin{itemize}
	\item операционная система: Kali \cite{kali} Linux \cite{linux} 5.16.0-kali7-amd64;
	\item оперативная память: 8 Гб;
	\item размер SWAP-файла \cite{swap} кэша: 4 Гб;
	\item SSD-накопитель \cite{ssd}: Samsung 980 NVMe M.2 512 Гб \cite{evo};
	\item процессор: Intel® Core™ i5-8250U \cite{intel} CPU @ 1.60GHz.
\end{itemize}

\subsection{Тестирование отказоустойчивости}

Было проведено исследование в области отказоустойчивости и проверки настроек СУБД Datomic при высоких нагрузках на инфраструктуру транзактора. Исследование проводилось при следующих настройках: для кэширования запросов на транзакторе на SSD-накопителе был выделен SWAP-файл размером 4 Гб, количество одновременно использующих базу пользователей увеличивалось до 100 с интервалом в 30 секунд и шагом 1, каждый подключённый пользователь совершал непрерывные запросы на запись и чтение. Инструментом исследования был выбран кластер в системе Kubernetes \cite{kuber}, позволяющий описать сценарий оркестрации приложений в едином конфигурационном файле и получать метрики в режиме реального времени. Результаты представлены на графиках \ref{plt:time} и \ref{plt:mem}.

\begin{figure}[!h]
	\centering
	\begin{tikzpicture}
		\begin{axis}[
			axis lines=left,
			xlabel=Количество подключений,
			ylabel={Количество запросов, шт/с.},
			legend pos=south east,
			ymajorgrids=true]
			\addplot table[x=count,y=transactor,col sep=comma]
			 {inc/csv/transactor.csv};
 			
 			\node[thick,red] at (87,194) {X};
			\legend{Производительность}
		\end{axis}
	\end{tikzpicture}
	\captionsetup{justification=centering}
	\caption{Количество операций в секунду.}
	\label{plt:time}
\end{figure}

\begin{figure}[!h]
	\centering
	\begin{tikzpicture}
		\begin{axis}[
			axis lines=left,
			xlabel=Количество подключений,
			ylabel={Количество памяти, Гб},
			legend pos=south east,
			ymajorgrids=true]
			\addplot table[x=count,y=mem,col sep=comma] {inc/csv/mem.csv};
			\node[thick,red] at (87,378) {X};
			\legend{Память}
		\end{axis}
	\end{tikzpicture}
	\captionsetup{justification=centering}
	\caption{Объём занимаемого кэша.}
	\label{plt:mem}
\end{figure}


На основе полученных данных установлена зависимость производительности системы от размера занятого кэша, при его переполнении система снижает свою производительность до 17\% в пике нагрузки. Это связано с особенностью кэширования: чем больше уникальных запросов, тем больше объёма занимает кэш. В ходе исследования вызвать отказ в обслуживании системы не удалось, устройство, на котором проводилось исследование, вышло из строя намного раньше инфраструктуры системы -- примерно на 87 подключённом пользователе вышел из строя SSD-накопитель, на котором был размещён кэш для транзактора, что привело к досрочному завершению исследования. Данные на графиках были экстраполированы для отображения недополученных результатов.